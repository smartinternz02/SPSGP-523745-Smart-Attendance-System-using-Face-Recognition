{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qz01PvKxgmT",
        "outputId": "4d6b7833-e42d-40be-c6c3-4b60522b6ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def load_dataset(dataset_dir):\n",
        "    face_images = []\n",
        "    face_labels = []\n",
        "\n",
        "    class_labels = sorted(os.listdir(dataset_dir))\n",
        "    for class_label in class_labels:\n",
        "        class_dir = os.path.join(dataset_dir, class_label)\n",
        "        if not os.path.isdir(class_dir):\n",
        "            continue\n",
        "\n",
        "        images = sorted(os.listdir(class_dir))\n",
        "        for image_name in images:\n",
        "            image_path = os.path.join(class_dir, image_name)\n",
        "            if not os.path.isfile(image_path):\n",
        "                continue\n",
        "\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                continue\n",
        "\n",
        "            face_images.append(image)\n",
        "            face_labels.append(class_label)\n",
        "\n",
        "    return face_images, face_labels\n",
        "\n",
        "# Provide the dataset directory path\n",
        "dataset_dir = \"/content/data/train\"\n",
        "\n",
        "# Load the dataset\n",
        "face_images, face_labels = load_dataset(dataset_dir)\n",
        "\n",
        "# Check the loaded data\n",
        "print(\"Total face images:\", len(face_images))\n",
        "print(\"Total face labels:\", len(face_labels))\n",
        "print(\"Example face label:\", face_labels[0])\n",
        "print(\"Example face image shape:\", face_images[0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpxV1EbA0K1q",
        "outputId": "c7915f24-384a-4ba0-c031-1a7cd371bf34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total face images: 112\n",
            "Total face labels: 112\n",
            "Example face label: Abhinav\n",
            "Example face image shape: (720, 1280, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "_qiZEusN3Wbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/data/train\"\n",
        "test_dir = \"/content/data/test\""
      ],
      "metadata": {
        "id": "gZI_-Gx435tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (64, 64)\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=image_size, batch_size=batch_size, class_mode=\"categorical\")\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, target_size=image_size, batch_size=batch_size, class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc4TJmvm35p9",
        "outputId": "5fd03410-b032-4059-d0ac-fab15439e623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 112 images belonging to 4 classes.\n",
            "Found 49 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPleaDtRw0zk",
        "outputId": "c416f0d7-e5e7-475b-c711-32ab88a0de69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Abhinav': 0, 'Akhil': 1, 'Akshith': 2, 'Dharan': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(train_generator.num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "SowiBDzw35kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BSzP1utR35g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "model.fit(train_generator, epochs=num_epochs, validation_data=test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBiKmRTv35ec",
        "outputId": "a8fb11cb-04a5-49ec-a6fa-12e1cd45fa0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 415ms/step - loss: 1.3421 - accuracy: 0.4018 - val_loss: 1.2744 - val_accuracy: 0.3061\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 340ms/step - loss: 1.1992 - accuracy: 0.4732 - val_loss: 1.1276 - val_accuracy: 0.3061\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 1.0656 - accuracy: 0.5179 - val_loss: 0.8982 - val_accuracy: 0.6122\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.7640 - accuracy: 0.7143 - val_loss: 0.5785 - val_accuracy: 0.6735\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 351ms/step - loss: 0.5394 - accuracy: 0.6696 - val_loss: 0.3300 - val_accuracy: 0.9592\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 323ms/step - loss: 0.3323 - accuracy: 0.8750 - val_loss: 0.3225 - val_accuracy: 0.7143\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.2461 - accuracy: 0.8839 - val_loss: 0.1555 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 0.1426 - accuracy: 0.9821 - val_loss: 0.1065 - val_accuracy: 0.9592\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.1151 - accuracy: 0.9732 - val_loss: 0.3043 - val_accuracy: 0.8163\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.1702 - accuracy: 0.9286 - val_loss: 0.1107 - val_accuracy: 0.9388\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f745554a440>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"face_recognition_model.h5\")"
      ],
      "metadata": {
        "id": "g8XXyzJ935b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "# Testing 1\n",
        "img1 = image.load_img('/content/data/test/Akhil/Akhil14.jpg',target_size=(64,64))\n",
        "img1 = image.img_to_array(img1)\n",
        "img1 = np.expand_dims(img1,axis=0)\n",
        "pred = np.argmax(model.predict(img1))\n",
        "print(pred)\n",
        "output = ['Abhinav', 'Akhil', 'Akshith', 'Dharan']\n",
        "print(output[pred])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hntWWC3Q35ZK",
        "outputId": "07c64f77-ea38-4f97-8fa1-ae724cc1cd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 208ms/step\n",
            "1\n",
            "Akhil\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 2\n",
        "img1 = image.load_img('/content/data/test/Abhinav/Abhinav9.jpg',target_size=(64,64))\n",
        "img1 = image.img_to_array(img1)\n",
        "img1 = np.expand_dims(img1,axis=0)\n",
        "pred = np.argmax(model.predict(img1))\n",
        "print(pred)\n",
        "output = ['Abhinav', 'Akhil', 'Akshith', 'Dharan']\n",
        "print(output[pred])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw3ir7kG49zJ",
        "outputId": "35b496ba-ebd1-4205-f154-4fdf300a2910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "0\n",
            "Abhinav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 3\n",
        "img1 = image.load_img('/content/data/test/Akshith/Akshith39.jpg',target_size=(64,64))\n",
        "img1 = image.img_to_array(img1)\n",
        "img1 = np.expand_dims(img1,axis=0)\n",
        "pred = np.argmax(model.predict(img1))\n",
        "print(pred)\n",
        "output = ['Abhinav', 'Akhil', 'Akshith', 'Dharan']\n",
        "print(output[pred])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeKRsGbS5ETS",
        "outputId": "d6435e28-bf23-4725-850d-d3dd3bfdad75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "2\n",
            "Akshith\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 4\n",
        "img1 = image.load_img('/content/data/test/Dharan/Dharan22.jpg',target_size=(64,64))\n",
        "img1 = image.img_to_array(img1)\n",
        "img1 = np.expand_dims(img1,axis=0)\n",
        "pred = np.argmax(model.predict(img1))\n",
        "print(pred)\n",
        "output = ['Abhinav', 'Akhil', 'Akshith', 'Dharan']\n",
        "print(output[pred])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANaj9KnI5RRP",
        "outputId": "598e3335-044b-4f06-a80f-765133213084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "3\n",
            "Dharan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"face_recognition_model.h5\")"
      ],
      "metadata": {
        "id": "HKgOTf0s8FjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-J9Kmsu8j_J",
        "outputId": "d2c325d9-b269-486c-b358-54e437b3b3ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               589952    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 683,716\n",
            "Trainable params: 683,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cmake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG-pNWANJytl",
        "outputId": "7eb97c68-a463-45d0-8a4d-272261717408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (3.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6k7uuIzJ25o",
        "outputId": "35720539-f3ce-4a7c-95d6-41a85077a949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install face_recognition==1.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiIbDfveJjvq",
        "outputId": "82cf98b6-5655-4fe7-ca2b-81d0f3898ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: face_recognition==1.3.0 in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition==1.3.0) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition==1.3.0) (8.1.3)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition==1.3.0) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition==1.3.0) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition==1.3.0) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "\n",
        "model = tf.keras.models.load_model('face_recognition_model.h5')\n",
        "\n",
        "image = face_recognition.load_image_file('/content/data/test/Akshith/Akshith16.jpg')\n",
        "face_locations = face_recognition.face_locations(image, model=\"hog\")\n",
        "face_encodings = face_recognition.face_encodings(image, face_locations)\n",
        "\n",
        "for face_encoding in face_encodings:\n",
        "    predictions = model.predict(np.expand_dims(face_encoding, axis=0))\n",
        "    class_index = np.argmax(predictions)\n",
        "    class_name = train_generator.class_indices[class_index]\n",
        "    print('Detected face belongs to:', class_name)\n"
      ],
      "metadata": {
        "id": "MJDpbOn0JBFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_faces = []\n",
        "labels = []\n"
      ],
      "metadata": {
        "id": "u_55i3Y19DSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model(\"face_recognition_model.h5\")\n",
        "\n",
        "# Set the path to the directory containing the dataset\n",
        "data_dir = \"/content/data/test\"  # Assuming you want to encode the faces from the test directory\n",
        "label_dir = \"/content/data/test\"\n",
        "# Define the image size\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Initialize empty lists for storing the encoded faces and labels\n",
        "encoded_faces = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through the directories in the data directory\n",
        "for label in os.listdir(data_dir):\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "    if os.path.isdir(label_dir):\n",
        "        # Iterate through the image files in each label directory\n",
        "        for filename in os.listdir(label_dir):\n",
        "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                # Load and preprocess the image\n",
        "                img_path = os.path.join(label_dir, filename)\n",
        "                img = image.load_img(img_path, target_size=image_size)\n",
        "                img = image.img_to_array(img)\n",
        "                img = np.expand_dims(img, axis=0)\n",
        "                img = img / 255.0  # Normalize the pixel values\n",
        "\n",
        "                # Encode the face using the trained model\n",
        "                encoding = model.predict(img)[0]\n",
        "\n",
        "                # Append the encoding and label to the lists\n",
        "                encoded_faces.append(encoding)\n",
        "                labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "encoded_faces = np.array(encoded_faces)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Print the shape of the encoded faces and labels arrays\n",
        "print(\"Encoded Faces Shape:\", encoded_faces.shape)\n",
        "print(\"Labels Shape:\", labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOTCQ7bl47Ty",
        "outputId": "7f362000-6373-4f38-864f-90b8ea4dfd61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 156ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Encoded Faces Shape: (49, 4)\n",
            "Labels Shape: (49,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AaEyX9xu5GnJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}